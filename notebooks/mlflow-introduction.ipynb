{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d546b38-f8b7-438d-9808-abfa3c61c993",
   "metadata": {},
   "source": [
    "# Tutorial : introduction to MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d0f60f-e70f-41f4-99ed-1e9800cfa9f7",
   "metadata": {},
   "source": [
    "This first application introduces the basic concepts of `MLFlow`. The goal is to predict the income class of individuals using a sample data from the US Census and a Random Forest classifier using the popular [scikit-learn](https://scikit-learn.org/stable/) machine learning `Python` library. \n",
    "\n",
    "We first illustrate how we would perform the training and fine-tuning of the model in a traditional way. Then, we show how we can integrate it as an **MLflow experiment**, so as to **log** relevant parameters and metrics in `MLflow`'s **tracking server** and visualize them in the UI. Finally, we illustrate how selected models can transition from the tracking server to the **model registry**, and how they can then be used from there to perform inference on new data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca2ed5cf-810d-47ea-ade3-f92f5e3771be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.pyfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ba85244-30af-43f4-92f2-a15bf67cf16b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b67a65-102f-4069-8cc8-4c64dcdc00ec",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed086e6",
   "metadata": {},
   "source": [
    "For this application, we'll use a classical dataset extracted from the 1994 US Census bureau data. The goal is to determine whether a person makes over $50K a year ('>50K') or less ('<=50K') using sociodemographic characteristics on the selected individuals. As the available variables are generally self-explanatory, we won't describe the data much, but more information on them can be found in the original [Kaggle challenge](https://www.kaggle.com/datasets/uciml/adult-census-income)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e24ae610-bb74-405b-9df0-06d423fd03c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_URL = \"https://minio.lab.sspcloud.fr/projet-formation/diffusion/mlops/data/adult-census-us.csv\"\n",
    "df_census = pd.read_csv(DATA_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "322565d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capitalgain</th>\n",
       "      <th>capitalloss</th>\n",
       "      <th>hoursperweek</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0    2         State-gov   77516  Bachelors             13   \n",
       "1    3  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2    2           Private  215646    HS-grad              9   \n",
       "3    3           Private  234721       11th              7   \n",
       "4    1           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capitalgain  capitalloss  hoursperweek native-country  class  \n",
       "0            1            0             2  United-States  <=50K  \n",
       "1            0            0             0  United-States  <=50K  \n",
       "2            0            0             2  United-States  <=50K  \n",
       "3            0            0             2  United-States  <=50K  \n",
       "4            0            0             2           Cuba  <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1291ee38",
   "metadata": {},
   "source": [
    "The goal is to predict the income class, so we must first set it aside from the training data. As this variable consists in string-encoded categories, we must encode it in a numerical format to be able to feed it to a machine learning model. A common practice for ordinal data (data for which an order exists, such as income class) is to encode labels as subsequent integers starting at 0, a technique known as **label encoding**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f30313ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "X = df_census.drop(columns=\"class\")\n",
    "y = le.fit_transform(df_census[\"class\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c770dee4",
   "metadata": {},
   "source": [
    "These new integer-encoded categories can naturally be mapped to the original values of the variable, and conversely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07fe46f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<=50K', '>50K'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The encoded classes\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c732d24c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 1]\n",
      "['<=50K' '<=50K' '<=50K' ... '<=50K' '<=50K' '>50K']\n"
     ]
    }
   ],
   "source": [
    "# The corresponding original classes\n",
    "print(y)\n",
    "print(np.array([le.classes_[i] for i in y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4f2f3e",
   "metadata": {},
   "source": [
    "A common practice in machine learning projects is to start by setting a fraction of the data aside as a **test dataset**. This data will be used at the very end of the project in order to properly evaluate the generalization performance of our selected algorithm, i.e. how it would perform on new unseen data. The rest of the data (**training dataset**) will be used to train the algorithms and compare their performance. Without this step, we are at risk of overfitting our models on the available data so that our evaluation metrics would no longer properly estimate the generalization error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89fded59-b6f4-4647-809b-643bef3b056a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c259a228",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 39073 entries, 22729 to 2732\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             39073 non-null  int64 \n",
      " 1   workclass       36830 non-null  object\n",
      " 2   fnlwgt          39073 non-null  int64 \n",
      " 3   education       39073 non-null  object\n",
      " 4   education-num   39073 non-null  int64 \n",
      " 5   marital-status  39073 non-null  object\n",
      " 6   occupation      36821 non-null  object\n",
      " 7   relationship    39073 non-null  object\n",
      " 8   race            39073 non-null  object\n",
      " 9   sex             39073 non-null  object\n",
      " 10  capitalgain     39073 non-null  int64 \n",
      " 11  capitalloss     39073 non-null  int64 \n",
      " 12  hoursperweek    39073 non-null  int64 \n",
      " 13  native-country  38404 non-null  object\n",
      "dtypes: int64(6), object(8)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab462d9",
   "metadata": {},
   "source": [
    "These general information show that thousands of observations are missing for some variables. To avoid wasting data and since these might not be missing-at-random, we'll impute values for the missing ones :\n",
    "- for numerical variables, we'll impute the median of the variable\n",
    "- for categorical variables, we'll impute the mode, i.e. the most frequent category in the data\n",
    "\n",
    "As previously, string-encoded categorical variables must also be converted to some form of numerical data. We'll use the same encoding strategy as the one used to encode the target variable.\n",
    "\n",
    "So as to make all these steps as reproducible as possible, we formalize them as a `scikit-learn` `Pipeline` object. More information on their justification and the way there are used can be found in the [documentation](https://scikit-learn.org/stable/modules/compose.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0135c24-826e-47e3-931c-7db4ec20b9dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "median_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "mode_imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "\n",
    "categorical_transformer = make_pipeline(mode_imputer, ordinal_encoder)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numerical\", median_imputer, make_column_selector(dtype_include=np.int64)),\n",
    "        (\"categorical\", categorical_transformer, make_column_selector(dtype_include=object))\n",
    "    ], remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ab4ca8",
   "metadata": {},
   "source": [
    "As most `scikit-learn` objects, the pipeline must first `fit` the data (e.g. compute the most frequent value or median). Then, we can use it to `transform` the data. The resulting object is a `NumPy` array with the same structure as the original data. It is not very useful per se, but it shows us that the categorical variables are indeed transformed into numerical values. This numerical array can then be fed to a machine learning model to train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58964862-1e9f-4fca-b158-4891057db7a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.17372e+05, 7.00000e+00, ..., 4.00000e+00,\n",
       "        1.00000e+00, 3.80000e+01],\n",
       "       [2.00000e+00, 3.57720e+05, 1.10000e+01, ..., 4.00000e+00,\n",
       "        0.00000e+00, 3.80000e+01],\n",
       "       [4.00000e+00, 2.02242e+05, 9.00000e+00, ..., 4.00000e+00,\n",
       "        1.00000e+00, 3.80000e+01],\n",
       "       ...,\n",
       "       [2.00000e+00, 3.44624e+05, 1.00000e+01, ..., 4.00000e+00,\n",
       "        1.00000e+00, 3.80000e+01],\n",
       "       [3.00000e+00, 1.04489e+05, 1.30000e+01, ..., 4.00000e+00,\n",
       "        1.00000e+00, 3.80000e+01],\n",
       "       [0.00000e+00, 1.86925e+05, 1.00000e+01, ..., 4.00000e+00,\n",
       "        1.00000e+00, 3.80000e+01]], shape=(39073, 14))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb81610-0b95-4dcd-96b0-ec2eebbc7281",
   "metadata": {},
   "source": [
    "## Tracking machine learning experiments : the classical way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506fd5be",
   "metadata": {},
   "source": [
    "In order to really understand why the MLOps approach is desirable, we must first get an idea of how we would train our model without it, i.e. the \"classical\" way. The workflow we are trying to achieve is best described by the following figure from the [scikit-learn documentation](https://scikit-learn.org/stable/).\n",
    "\n",
    "<img src=\"img/grid_search_workflow.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "Using the training data, we want to train a model so as to get the best generalization performance, i.e. minimize the prediction error on unseen data. To do so, we have to **fine-tune** the **hyperparameters** of our model, i.e. find the combination of **hyperparameters** that provide the best performance. In order to avoid **overfitting** when doing so, we use a procedure called **cross-validation** (described in details [here](https://scikit-learn.org/stable/modules/cross_validation.html)). When we have found the optimal set of hyperparameters, we use the model trained with those for a final evaluation on the test set.\n",
    "\n",
    "In this example, we train a *Random Forest* to discriminate the two income classes. First, we build a `Pipeline` object that integrates the preprocessing step as well as the model, so as to be able to improve reproducibility of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef674c48-5111-40af-81d4-02c0ec18ad22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=SEED)\n",
    "\n",
    "pipe_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('classifier', rf_clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39f87d5",
   "metadata": {},
   "source": [
    "Although the hyperparameters provided natively by `scikit-learn` are usually good defaults, we will of course want to check whether we can improve the performance further by **fine-tuning** the relevant hyperparameters. To do so, we use the *grid search* method, which amounts to testing all the possible hyperparameters combinations along given values (*grid*) for these hyperparameters. For each combination, a performance evaluation is performed using a 5-folds *cross-validation*. As the accuracy is rarely a relevant metric for classification problems because of class imbalance, we also request the precision, the recall and the f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "819fa1df-292f-4c3d-b9af-c2e164f391a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"classifier__n_estimators\": [50, 100, 200],\n",
    "    \"classifier__max_leaf_nodes\": [5, 10, 50]\n",
    "}\n",
    "\n",
    "pipe_gscv = GridSearchCV(pipe_rf, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"accuracy\", \"precision\", \"recall\", \"f1\"],\n",
    "                         refit=\"f1\",\n",
    "                         cv=5, \n",
    "                         n_jobs=5, \n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74c3f16",
   "metadata": {},
   "source": [
    "**Question** : can you guess the total number of `fit` steps that will be performed when calling the `fit` method on the `pipe_gscv` object ?\n",
    "\n",
    "<details>\n",
    "<summary>\n",
    "    <font size=\\\"3\\\" color=\\\"darkgreen\\\"><b>Click to see the answer </b></font>\n",
    "</summary>\n",
    "\n",
    "From the grid search only, there are 3 * 3 = 9 candidate models to train. However, for each combination, a 5-folds cross-validation is performed, which involves 5 training steps (*fits*). So altogether, there will be 9 * 5 = 45 *fits* to compute.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd56281e-31dc-4a24-940e-6eb180aad8f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                          transformers=[(&#x27;numerical&#x27;,\n",
       "                                                                         SimpleImputer(strategy=&#x27;median&#x27;),\n",
       "                                                                         &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f1c0d316a20&gt;),\n",
       "                                                                        (&#x27;categorical&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                          SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                         (&#x27;ordinalencoder&#x27;,\n",
       "                                                                                          OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                                                         unknown_value=-1))]),\n",
       "                                                                         &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f1c0d317350&gt;)])),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        RandomForestClassifier(random_state=0))]),\n",
       "             n_jobs=5,\n",
       "             param_grid={&#x27;classifier__max_leaf_nodes&#x27;: [5, 10, 50],\n",
       "                         &#x27;classifier__n_estimators&#x27;: [50, 100, 200]},\n",
       "             refit=&#x27;f1&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;f1&#x27;],\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                          transformers=[(&#x27;numerical&#x27;,\n",
       "                                                                         SimpleImputer(strategy=&#x27;median&#x27;),\n",
       "                                                                         &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f1c0d316a20&gt;),\n",
       "                                                                        (&#x27;categorical&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                          SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                         (&#x27;ordinalencoder&#x27;,\n",
       "                                                                                          OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                                                         unknown_value=-1))]),\n",
       "                                                                         &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f1c0d317350&gt;)])),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        RandomForestClassifier(random_state=0))]),\n",
       "             n_jobs=5,\n",
       "             param_grid={&#x27;classifier__max_leaf_nodes&#x27;: [5, 10, 50],\n",
       "                         &#x27;classifier__n_estimators&#x27;: [50, 100, 200]},\n",
       "             refit=&#x27;f1&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;f1&#x27;],\n",
       "             verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;numerical&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f1c0d3edd60&gt;),\n",
       "                                                 (&#x27;categorical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;ordinalencoder&#x27;,\n",
       "                                                                   OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                                  unknown_value=-1))]),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f1c0d3ed190&gt;)])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 RandomForestClassifier(max_leaf_nodes=50, n_estimators=50,\n",
       "                                        random_state=0))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>preprocessor: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;numerical&#x27;, SimpleImputer(strategy=&#x27;median&#x27;),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f1c0d3edd60&gt;),\n",
       "                                (&#x27;categorical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;ordinalencoder&#x27;,\n",
       "                                                  OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                 unknown_value=-1))]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f1c0d3ed190&gt;)])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>numerical</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f1c0d3edd60&gt;</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SimpleImputer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>categorical</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f1c0d3ed190&gt;</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SimpleImputer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OrdinalEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OrdinalEncoder.html\">?<span>Documentation for OrdinalEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;, unknown_value=-1)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>remainder</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>passthrough</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>passthrough</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_leaf_nodes=50, n_estimators=50, random_state=0)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(remainder='passthrough',\n",
       "                                                          transformers=[('numerical',\n",
       "                                                                         SimpleImputer(strategy='median'),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x7f1c0d316a20>),\n",
       "                                                                        ('categorical',\n",
       "                                                                         Pipeline(steps=[('simpleimputer',\n",
       "                                                                                          SimpleImputer(strategy='most_frequent')),\n",
       "                                                                                         ('ordinalencoder',\n",
       "                                                                                          OrdinalEncoder(handle_unknown='use_encoded_value',\n",
       "                                                                                                         unknown_value=-1))]),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x7f1c0d317350>)])),\n",
       "                                       ('classifier',\n",
       "                                        RandomForestClassifier(random_state=0))]),\n",
       "             n_jobs=5,\n",
       "             param_grid={'classifier__max_leaf_nodes': [5, 10, 50],\n",
       "                         'classifier__n_estimators': [50, 100, 200]},\n",
       "             refit='f1', scoring=['accuracy', 'precision', 'recall', 'f1'],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_gscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f217e9ab",
   "metadata": {},
   "source": [
    "We can get detailed results for each candidate model in a `Pandas DataFrame`. This enables us to compare the models and select the best candidate based on their respective performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4541f8d2-7fac-4407-928d-b70c3640fa8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__max_leaf_nodes</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_recall</th>\n",
       "      <th>rank_test_recall</th>\n",
       "      <th>split0_test_f1</th>\n",
       "      <th>split1_test_f1</th>\n",
       "      <th>split2_test_f1</th>\n",
       "      <th>split3_test_f1</th>\n",
       "      <th>split4_test_f1</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>std_test_f1</th>\n",
       "      <th>rank_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.665763</td>\n",
       "      <td>0.039751</td>\n",
       "      <td>0.050488</td>\n",
       "      <td>0.004063</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'classifier__max_leaf_nodes': 5, 'classifier_...</td>\n",
       "      <td>0.827639</td>\n",
       "      <td>0.833781</td>\n",
       "      <td>0.832118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013073</td>\n",
       "      <td>7</td>\n",
       "      <td>0.541993</td>\n",
       "      <td>0.545963</td>\n",
       "      <td>0.543811</td>\n",
       "      <td>0.557421</td>\n",
       "      <td>0.528157</td>\n",
       "      <td>0.543469</td>\n",
       "      <td>0.009356</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.166971</td>\n",
       "      <td>0.046580</td>\n",
       "      <td>0.057482</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'classifier__max_leaf_nodes': 5, 'classifier_...</td>\n",
       "      <td>0.825080</td>\n",
       "      <td>0.831734</td>\n",
       "      <td>0.827895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007155</td>\n",
       "      <td>8</td>\n",
       "      <td>0.514732</td>\n",
       "      <td>0.536809</td>\n",
       "      <td>0.523557</td>\n",
       "      <td>0.530239</td>\n",
       "      <td>0.517448</td>\n",
       "      <td>0.524557</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.311294</td>\n",
       "      <td>0.142730</td>\n",
       "      <td>0.079847</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__max_leaf_nodes': 5, 'classifier_...</td>\n",
       "      <td>0.823800</td>\n",
       "      <td>0.828279</td>\n",
       "      <td>0.825848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005810</td>\n",
       "      <td>9</td>\n",
       "      <td>0.503067</td>\n",
       "      <td>0.520714</td>\n",
       "      <td>0.514449</td>\n",
       "      <td>0.513224</td>\n",
       "      <td>0.512221</td>\n",
       "      <td>0.512735</td>\n",
       "      <td>0.005667</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.766281</td>\n",
       "      <td>0.044100</td>\n",
       "      <td>0.046806</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'classifier__max_leaf_nodes': 10, 'classifier...</td>\n",
       "      <td>0.831862</td>\n",
       "      <td>0.841331</td>\n",
       "      <td>0.837876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010626</td>\n",
       "      <td>4</td>\n",
       "      <td>0.567763</td>\n",
       "      <td>0.595828</td>\n",
       "      <td>0.590894</td>\n",
       "      <td>0.574122</td>\n",
       "      <td>0.583145</td>\n",
       "      <td>0.582351</td>\n",
       "      <td>0.010351</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.372333</td>\n",
       "      <td>0.052957</td>\n",
       "      <td>0.062584</td>\n",
       "      <td>0.001889</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'classifier__max_leaf_nodes': 10, 'classifier...</td>\n",
       "      <td>0.831094</td>\n",
       "      <td>0.840691</td>\n",
       "      <td>0.837236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009021</td>\n",
       "      <td>5</td>\n",
       "      <td>0.564931</td>\n",
       "      <td>0.591401</td>\n",
       "      <td>0.587281</td>\n",
       "      <td>0.575057</td>\n",
       "      <td>0.577098</td>\n",
       "      <td>0.579154</td>\n",
       "      <td>0.009374</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.665763      0.039751         0.050488        0.004063   \n",
       "1       1.166971      0.046580         0.057482        0.002089   \n",
       "2       2.311294      0.142730         0.079847        0.002048   \n",
       "3       0.766281      0.044100         0.046806        0.004972   \n",
       "4       1.372333      0.052957         0.062584        0.001889   \n",
       "\n",
       "   param_classifier__max_leaf_nodes  param_classifier__n_estimators  \\\n",
       "0                                 5                              50   \n",
       "1                                 5                             100   \n",
       "2                                 5                             200   \n",
       "3                                10                              50   \n",
       "4                                10                             100   \n",
       "\n",
       "                                              params  split0_test_accuracy  \\\n",
       "0  {'classifier__max_leaf_nodes': 5, 'classifier_...              0.827639   \n",
       "1  {'classifier__max_leaf_nodes': 5, 'classifier_...              0.825080   \n",
       "2  {'classifier__max_leaf_nodes': 5, 'classifier_...              0.823800   \n",
       "3  {'classifier__max_leaf_nodes': 10, 'classifier...              0.831862   \n",
       "4  {'classifier__max_leaf_nodes': 10, 'classifier...              0.831094   \n",
       "\n",
       "   split1_test_accuracy  split2_test_accuracy  ...  std_test_recall  \\\n",
       "0              0.833781              0.832118  ...         0.013073   \n",
       "1              0.831734              0.827895  ...         0.007155   \n",
       "2              0.828279              0.825848  ...         0.005810   \n",
       "3              0.841331              0.837876  ...         0.010626   \n",
       "4              0.840691              0.837236  ...         0.009021   \n",
       "\n",
       "   rank_test_recall  split0_test_f1  split1_test_f1  split2_test_f1  \\\n",
       "0                 7        0.541993        0.545963        0.543811   \n",
       "1                 8        0.514732        0.536809        0.523557   \n",
       "2                 9        0.503067        0.520714        0.514449   \n",
       "3                 4        0.567763        0.595828        0.590894   \n",
       "4                 5        0.564931        0.591401        0.587281   \n",
       "\n",
       "   split3_test_f1  split4_test_f1  mean_test_f1  std_test_f1  rank_test_f1  \n",
       "0        0.557421        0.528157      0.543469     0.009356             7  \n",
       "1        0.530239        0.517448      0.524557     0.008130             8  \n",
       "2        0.513224        0.512221      0.512735     0.005667             9  \n",
       "3        0.574122        0.583145      0.582351     0.010351             4  \n",
       "4        0.575057        0.577098      0.579154     0.009374             5  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv_results = pd.DataFrame(pipe_gscv.cv_results_)\n",
    "gscv_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb75b873",
   "metadata": {},
   "source": [
    "The fitted `Pipeline` object actually keep tracks of the best model for us. We can thus show the best performing set of hyperparameters, and use the model trained with these hyperparameters to compute the final score on the test set (not used until yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23990354-0989-454f-a1d3-c2f230d82d37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__max_leaf_nodes': 50, 'classifier__n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "print(pipe_gscv.best_params_)\n",
    "\n",
    "best_model = pipe_gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1042c22b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final F1-score on test data : 0.6464339908952959\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Final F1-score on test data : {f1_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e06080",
   "metadata": {},
   "source": [
    "In order for this analysis to be reproducible, we must find a way to export the results. Fortunately, `scikit-learn` models are serializable. One way to persist them is to use `joblib` (see the [documentation on model persistence](https://scikit-learn.org/stable/model_persistence.html) for a more detailed discussion on possible way to export models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ca46c05-9f19-4269-9311-ccb547d40ffa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/pipeline_train_model_20230118.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(\"models/\"):\n",
    "    os.makedirs(\"models/\")\n",
    "joblib.dump(pipe_gscv, 'models/pipeline_train_model_20230118.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f985c76",
   "metadata": {},
   "source": [
    "This is convenient for the development phase, but it is also very clear that **this way of persisting models is not production-grade nor scalable** :\n",
    "- first and foremost, we lack a proper way to **track experiments** (data used for training, environment configuration, metrics...)\n",
    "- we can not easily visualize the various metrics so as to compare and select the best model\n",
    "- we can parallelize the cross-validation computation, but we can't readily parallelize the evaluation of each hyperparameters combination\n",
    "- there is no easy and standardized way to distribute the serialized models, so the collaboration of several team members on a given experiment is complicated\n",
    "\n",
    "The MLOps principles were precisely devised to solve these various problems. Let's see now how MLflow enables us to implement them easily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbc5b57-6dcc-4bf1-a2c3-29ae13300e46",
   "metadata": {},
   "source": [
    "## Tracking machine learning experiments : the MLFlow way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259b194e-cbdf-463a-a7fd-e71ce0ddae19",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c359c4",
   "metadata": {},
   "source": [
    "The main component of `MLflow` is the *Tracking Server*, which tracks experiments and save the relevant data and metadata. More precisely, for each *run* (\"execution of some piece of data science code\"), the *Tracking Server* records : \n",
    "- **experiments data** (parameters, metrics, tags, notes, metadata, ...) in a **backend store** (in our case, a `PostgreSQL` database)\n",
    "- **artifacts** (models, files, images, ...) in an **artifact store** (in our case, `S3`-like storage)\n",
    "\n",
    "As a user, we communicate with the *Tracking Server* through a client (in our case, a `Jupyter` notebook with a `Python` kernel).\n",
    "\n",
    "Fortunately, in a properly set up environment, these three communication levels can be pre-configured so that they are relatively transparent to the user. This enables the data scientist to focus on the business task at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c0dc8f",
   "metadata": {},
   "source": [
    "<img src=\"img/mlflow-tracking.png\" alt=\"Drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a155b49",
   "metadata": {},
   "source": [
    "The client must know the URI of the *tracking server*. If a `MLflow` instance has been launched on the SSP Cloud previous to the client, the client will automatically discover the URI. If not, it must be set manually. Opening this URL opens the UI of `MLflow`, which we will be using later in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91a2e959",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://user-raphaelmasure-mlflow.user.lab.sspcloud.fr\n"
     ]
    }
   ],
   "source": [
    "# Automatic discovery : if MLFlow has been launched before Jupyter/VSCode\n",
    "if \"MLFLOW_TRACKING_URI\" in os.environ:\n",
    "    print(os.environ[\"MLFLOW_TRACKING_URI\"])\n",
    "else:\n",
    "    print(\"MLflow was not automatically discovered, a tracking URI must be provided manually.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15061562-8b91-45c4-8ada-f8458873e513",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Manual configuration : if MLFlow has been launched after Jupyter/VSCode\n",
    "# os.environ[\"MLFLOW_TRACKING_URI\"] = \"copy_uri_from_mlflow_service_README_here\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b55dd7-1f2c-42fa-941d-bad8412cdd16",
   "metadata": {},
   "source": [
    "### Tracking experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa949cb-bf32-4ce7-9bfe-7b7dc3ec00df",
   "metadata": {},
   "source": [
    "In the previous steps, we fine-tuned our model, i.e. we trained the same model with several different combinations of hyper-parameters in order to ultimately select the one with the best performance according to a given metric. In comparison with the \"traditional way\" we saw above, `MLflow` enables us to track these experiments in a much more refined way, compatible with the *MLOps* principles.\n",
    "\n",
    "The function `log_gsvc_to_mlflow` below enables us to convert the data contained in our `GridSearchCV` object (hyperparameters, metrics, artifact..) into an `MLflow` experiment, which can then be queried using the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abd9585f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log_gsvc_to_mlflow(gscv, mlflow_experiment_name):\n",
    "    \"\"\"Log a scikit-learn trained GridSearchCV object as an MLflow experiment.\"\"\"\n",
    "     # Set up MLFlow context\n",
    "    mlflow.set_experiment(experiment_name=mlflow_experiment_name)\n",
    "\n",
    "    for run_idx in range(len(gscv.cv_results_[\"params\"])):\n",
    "        # For each hyperparameter combination we trained the model with, we log a run in MLflow\n",
    "        run_name = f\"run {run_idx}\"\n",
    "        with mlflow.start_run(run_name=run_name):\n",
    "            # Log hyperparameters\n",
    "            params = gscv.cv_results_[\"params\"][run_idx]\n",
    "            for param in params:\n",
    "                mlflow.log_param(param, params[param])\n",
    "\n",
    "            # Log fit metrics\n",
    "            scores = [score for score in gscv.cv_results_ if \"mean_test\" in score or \"std_test\" in score]\n",
    "            for score in scores:\n",
    "                mlflow.log_metric(score, gscv.cv_results_[score][run_idx])\n",
    "\n",
    "            # Log model as an artifact\n",
    "            mlflow.sklearn.log_model(gscv, \"gscv_model\")\n",
    "\n",
    "            # Log training data URL\n",
    "            mlflow.log_param(\"data_url\", DATA_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a5f397a-1d6d-47de-94ca-29a2957c3427",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/04/01 09:01:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run run 0 at: https://user-raphaelmasure-mlflow.user.lab.sspcloud.fr/#/experiments/1/runs/531bd7d8a75042c9bc33ecdb8d65454e\n",
      "🧪 View experiment at: https://user-raphaelmasure-mlflow.user.lab.sspcloud.fr/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/04/01 09:01:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run run 1 at: https://user-raphaelmasure-mlflow.user.lab.sspcloud.fr/#/experiments/1/runs/26e0c24c786645c58c2be5c6ed1e7bf5\n",
      "🧪 View experiment at: https://user-raphaelmasure-mlflow.user.lab.sspcloud.fr/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/04/01 09:01:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run run 2 at: https://user-raphaelmasure-mlflow.user.lab.sspcloud.fr/#/experiments/1/runs/e1e115c0503f44cfa989c0a15aaeec8b\n",
      "🧪 View experiment at: https://user-raphaelmasure-mlflow.user.lab.sspcloud.fr/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/04/01 09:01:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run run 3 at: https://user-raphaelmasure-mlflow.user.lab.sspcloud.fr/#/experiments/1/runs/4b9893d7d44e4439b045edb7548cee37\n",
      "🧪 View experiment at: https://user-raphaelmasure-mlflow.user.lab.sspcloud.fr/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/04/01 09:01:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run run 4 at: https://user-raphaelmasure-mlflow.user.lab.sspcloud.fr/#/experiments/1/runs/74a98b1cd3ee47cf93d431345f850d7d\n",
      "🧪 View experiment at: https://user-raphaelmasure-mlflow.user.lab.sspcloud.fr/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/04/01 09:01:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run run 5 at: https://user-raphaelmasure-mlflow.user.lab.sspcloud.fr/#/experiments/1/runs/fa47ecb4565d4b0b9fae22a6317a0250\n",
      "🧪 View experiment at: https://user-raphaelmasure-mlflow.user.lab.sspcloud.fr/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/04/01 09:01:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run run 6 at: https://user-raphaelmasure-mlflow.user.lab.sspcloud.fr/#/experiments/1/runs/33af0cf0fd534038a9bfc8201dd0a577\n",
      "🧪 View experiment at: https://user-raphaelmasure-mlflow.user.lab.sspcloud.fr/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/04/01 09:01:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run run 7 at: https://user-raphaelmasure-mlflow.user.lab.sspcloud.fr/#/experiments/1/runs/83b00017c1554cb0b4da70c012619653\n",
      "🧪 View experiment at: https://user-raphaelmasure-mlflow.user.lab.sspcloud.fr/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/04/01 09:01:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run run 8 at: https://user-raphaelmasure-mlflow.user.lab.sspcloud.fr/#/experiments/1/runs/e42495d1e9184843989c1f039dcafdd1\n",
      "🧪 View experiment at: https://user-raphaelmasure-mlflow.user.lab.sspcloud.fr/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "log_gsvc_to_mlflow(gscv=pipe_gscv, mlflow_experiment_name=\"tutorial-mlflow-intro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7228d7-d1ca-4188-9a7d-c3effff3e693",
   "metadata": {},
   "source": [
    "### Application 1.1: Tracking models with MLflow\n",
    "\n",
    "If the previous cell executed correctly, that means the experiments and in particular all the data we wanted `MLflow` to log are now available in the *tracking server*. In order to interact with these data and try to select the best model, we'll learn to use the UI. Please follow the following steps :\n",
    "1. Open the UI using the URI we printed above\n",
    "2. In the *Experiments* tab, open the \"tutorial-mlflow-intro\" experiment\n",
    "3. Verify that there are indeed 9 runs that have been recorded, one for each hyperparameters combination\n",
    "4. Open a given run and verify that you can retrieve the various information we wanted to log (hyperparameters, evaluation metrics, training data URL), check that you can download the serialized `scikit-learn` model, and check the `requirements.txt` file to understand how `MLflow` automatically inferred the required `Python` environment\n",
    "5. Go back to the list of runs by clicking again on the \"tutorial-mlflow-intro\" experiment\n",
    "6. Add additional columns using the *Columns* drop-down menu in the *Table* panel\n",
    "7. Sort the models in descending order according to the **mean test F1-score** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b48f501-3446-49af-b75b-b53dbd84fc3b",
   "metadata": {},
   "source": [
    "### Application 1.2: Registering a model with MLflow\n",
    "In the previous section, we logged properly our experiment in the `MLflow` tracking server, which enables to compare our models and see the best performing ones in a visual way. Now, we want to be able to select a model, put it in production, and allow the other members of the projet to query it. For this to be possible, we have to **move the model from the tracking server to the model registry**.\n",
    "1. Consider both the high mean test F1-score and low standard deviation of test F1-score to make a decision on the best model.\n",
    "2. Click on the run corresponding to your chosen best model.\n",
    "3. Click on \"Register Model\"\n",
    "4. Create a New Model and give it a relevant name (e.g. \"rf-census\")\n",
    "5. Move to the model registry by clicking on the \"Models\" tab\n",
    "6. If everything worked correctly, you should see your model in the list of the registered models. Click on it to get the list of the registered versions of the model. For now, there is only one version as we pushed it only one time.\n",
    "7. Click on \"Version 1\" to get the information on this specific version of the model. Two things are especially interesting to note :\n",
    "\n",
    "   **a.** The \"Stage\" section. Here you can indicate to all members of the project what is stage of this specific model. Let's transition it to \"Production\" to indicate that is our reference model, which we want to deploy\n",
    "\n",
    "   **b.** The \"Source run\" section. Here you can retrieve the run that corresponds to this model. If you click on the run id, you retrieve all the information we logged (environment, metrics, artifacts location...). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de39735-cd52-46bb-9559-81c6f393b3c5",
   "metadata": {},
   "source": [
    "### Querying a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d910ff9-4b0c-46f0-8d5f-47c5a6b49a79",
   "metadata": {},
   "source": [
    "As above, let's perform the final evaluation on the test set using the model we put in production. We can retrieve the model either by its version or by its stage, should it have one. We fetch the model using the `mlflow.pyfunc.load_model` function. We then have our `scikit-learn` model, which can directly be used for prediction. Let's check that we find the same final F1-score on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b4d454-6e9d-4a18-a144-ec534a647dc6",
   "metadata": {},
   "source": [
    "#### Using the version number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b7520d8-8e7c-418e-acb6-5daac6ecc2ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|██████████| 5/5 [00:00<00:00, 18.86it/s]\n",
      "2025/04/01 09:01:57 WARNING mlflow.utils.requirements_utils: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - mlflow (current: 2.19.0, required: mlflow==2.20.4)\n",
      " - numpy (current: 2.2.4, required: numpy==2.2.3)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n"
     ]
    }
   ],
   "source": [
    "# Fetch the model\n",
    "model_name = \"rf-census\"\n",
    "version = 1\n",
    "\n",
    "model = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ecfcbe7-2a23-47ea-8b75-d910fbae51ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final F1-score on test data : 0.6464339908952959\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation\n",
    "y_test_pred = model.predict(X_test)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Final F1-score on test data : {f1_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7391615-3290-47b8-a3b2-f7c9662774f9",
   "metadata": {},
   "source": [
    "This score indeed corresponds to the one we found in the \"classical ML training\" section using the best trained model !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb1adeb-04ae-43c7-90a1-e09212e8063b",
   "metadata": {},
   "source": [
    "#### Using the stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb635aa-2a6f-4acb-b411-c8d71af2878d",
   "metadata": {},
   "source": [
    "Equivalently, we can use the stage of the model, which should produce the same score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a266fc1a-b560-4125-a9c8-0dee5c71ae98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/mlflow/store/artifact/utils/models.py:31: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  latest = client.get_latest_versions(name, None if stage is None else [stage])\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "No versions of model with name 'rf-census' and stage 'Production' found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMlflowException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mrf-census\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m stage = \u001b[33m'\u001b[39m\u001b[33mProduction\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m model = \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpyfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodels:/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mstage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/mlflow/tracing/provider.py:309\u001b[39m, in \u001b[36mtrace_disabled.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    307\u001b[39m disable()\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m     is_func_called, result = \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    311\u001b[39m     enable()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/mlflow/pyfunc/__init__.py:1033\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(model_uri, suppress_warnings, dst_path, model_config)\u001b[39m\n\u001b[32m   1029\u001b[39m         entity_list.append(Entity(job=job_entity))\n\u001b[32m   1031\u001b[39m     lineage_header_info = LineageHeaderInfo(entities=entity_list) \u001b[38;5;28;01mif\u001b[39;00m entity_list \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1033\u001b[39m local_path = \u001b[43m_download_artifact_from_uri\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m    \u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdst_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlineage_header_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineage_header_info\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1037\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m suppress_warnings:\n\u001b[32m   1038\u001b[39m     model_requirements = _get_pip_requirements_from_model_path(local_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/mlflow/tracking/artifact_utils.py:108\u001b[39m, in \u001b[36m_download_artifact_from_uri\u001b[39m\u001b[34m(artifact_uri, output_path, lineage_header_info)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[33;03m    artifact_uri: The *absolute* URI of the artifact to download.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    105\u001b[39m \u001b[33;03m    lineage_header_info: The model lineage header info to be consumed by lineage services.\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    107\u001b[39m root_uri, artifact_path = _get_root_uri_and_artifact_path(artifact_uri)\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m repo = \u001b[43mget_artifact_repository\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[43mroot_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(repo, ModelsArtifactRepository):\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m repo.download_artifacts(\n\u001b[32m    112\u001b[39m         artifact_path=artifact_path,\n\u001b[32m    113\u001b[39m         dst_path=output_path,\n\u001b[32m    114\u001b[39m         lineage_header_info=lineage_header_info,\n\u001b[32m    115\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/mlflow/store/artifact/artifact_repository_registry.py:131\u001b[39m, in \u001b[36mget_artifact_repository\u001b[39m\u001b[34m(artifact_uri)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_artifact_repository\u001b[39m(artifact_uri: \u001b[38;5;28mstr\u001b[39m) -> ArtifactRepository:\n\u001b[32m    119\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    120\u001b[39m \u001b[33;03m    Get an artifact repository from the registry based on the scheme of artifact_uri\u001b[39;00m\n\u001b[32m    121\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    129\u001b[39m \u001b[33;03m        requirements.\u001b[39;00m\n\u001b[32m    130\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_artifact_repository_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_artifact_repository\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/mlflow/store/artifact/artifact_repository_registry.py:76\u001b[39m, in \u001b[36mArtifactRepositoryRegistry.get_artifact_repository\u001b[39m\u001b[34m(self, artifact_uri)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m repository \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m     73\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not find a registered artifact repository for: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00martifact_uri\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     74\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCurrently registered schemes are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m._registry.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     75\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrepository\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/mlflow/store/artifact/models_artifact_repo.py:69\u001b[39m, in \u001b[36mModelsArtifactRepository.__init__\u001b[39m\u001b[34m(self, artifact_uri)\u001b[39m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28mself\u001b[39m.model_version = \u001b[38;5;28mself\u001b[39m.repo.model_version\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     65\u001b[39m     (\n\u001b[32m     66\u001b[39m         \u001b[38;5;28mself\u001b[39m.model_name,\n\u001b[32m     67\u001b[39m         \u001b[38;5;28mself\u001b[39m.model_version,\n\u001b[32m     68\u001b[39m         underlying_uri,\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     ) = \u001b[43mModelsArtifactRepository\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_model_uri_infos\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m     \u001b[38;5;28mself\u001b[39m.repo = get_artifact_repository(underlying_uri)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/mlflow/store/artifact/models_artifact_repo.py:107\u001b[39m, in \u001b[36mModelsArtifactRepository._get_model_uri_infos\u001b[39m\u001b[34m(uri)\u001b[39m\n\u001b[32m    103\u001b[39m databricks_profile_uri = (\n\u001b[32m    104\u001b[39m     get_databricks_profile_uri_from_artifact_uri(uri) \u001b[38;5;129;01mor\u001b[39;00m mlflow.get_registry_uri()\n\u001b[32m    105\u001b[39m )\n\u001b[32m    106\u001b[39m client = MlflowClient(registry_uri=databricks_profile_uri)\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m name, version = \u001b[43mget_model_name_and_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m download_uri = client.get_model_version_download_uri(name, version)\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m    111\u001b[39m     name,\n\u001b[32m    112\u001b[39m     version,\n\u001b[32m    113\u001b[39m     add_databricks_profile_info_to_artifact_uri(download_uri, databricks_profile_uri),\n\u001b[32m    114\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/mlflow/store/artifact/utils/models.py:93\u001b[39m, in \u001b[36mget_model_name_and_version\u001b[39m\u001b[34m(client, models_uri)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_alias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model_name, client.get_model_version_by_alias(model_name, model_alias).version\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model_name, \u001b[38;5;28mstr\u001b[39m(\u001b[43m_get_latest_model_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_stage\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/mlflow/store/artifact/utils/models.py:34\u001b[39m, in \u001b[36m_get_latest_model_version\u001b[39m\u001b[34m(client, name, stage)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(latest) == \u001b[32m0\u001b[39m:\n\u001b[32m     33\u001b[39m     stage_str = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stage \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m and stage \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo versions of model with name \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstage_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m found\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mint\u001b[39m(x.version) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m latest)\n",
      "\u001b[31mMlflowException\u001b[39m: No versions of model with name 'rf-census' and stage 'Production' found"
     ]
    }
   ],
   "source": [
    "# Fetch the model\n",
    "model_name = \"rf-census\"\n",
    "stage = 'Production'\n",
    "\n",
    "model = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{stage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7615eb88-187a-4af8-8d5f-86a907462f63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Final evaluation\n",
    "y_test_pred = model.predict(X_test)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Final F1-score on test data : {f1_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b0c365-d352-4748-a5dc-44cb144d490a",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14e1325-5566-4816-95ac-d0c6c69791cf",
   "metadata": {},
   "source": [
    "`MLflow` enables us to **set our machine learning experiments to the standards of the `MLOps` approach** in a very user-friendly way :\n",
    "- data scientists can very easily decide what data they want to log for each experiment so as to **keep a detailed track of those experiments**\n",
    "- other members of the team (e.g. data engineers that might be in charge of deploying the model) can very easily fetch the model and use it for prediction in an application. To do so, they only need to know the name of the model as well as its version or its stage, but not the actual location of the artifact on the storage, as this layer is abstracted by `MLflow`. **This makes collaboration on machine learning projects very convenient and efficient**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aaa7d9-4ae6-42da-8de7-de6026b73e56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
